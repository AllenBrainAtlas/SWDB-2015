{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# writing strings to files\n",
    "This is the most flexible, but unstructured, way to save data.  Unless you're really only saving a text file, you're going to have to come up with some way to encode your data.  There are better options for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to save this text to a file.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "out_data = \"I want to save this text to a file.\"\n",
    "\n",
    "# without a directory, this will go into your current working directory\n",
    "file_name = 'test_file.txt'\n",
    "\n",
    "# write it out\n",
    "with open(file_name, 'w') as f:\n",
    "    f.write(out_data)\n",
    "\n",
    "# read it back in\n",
    "with open(file_name, 'r') as f:\n",
    "    in_data = f.read()\n",
    "    \n",
    "print in_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving 'string1' to 'test_file_0.txt'\n",
      "saving 'string2' to 'test_file_1.txt'\n",
      "saving 'string3' to 'test_file_2.txt'\n"
     ]
    }
   ],
   "source": [
    "# i want to save these to separate files\n",
    "out_data = ['string1', 'string2', 'string3' ]\n",
    "\n",
    "for i, d in enumerate(out_data):\n",
    "    # let's make a unique file name for each string\n",
    "    file_name = 'test_file_%d.txt' % i\n",
    "    \n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(d)    \n",
    "        print \"saving '%s' to '%s'\" % (d, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV files\n",
    "The simplest way to store tabular data.  If your data structures are flat (not nested) and not too big, go ahead and use this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'age']\n",
      "['jim', '10']\n",
      "['bob', '20']\n",
      "['jill', '30']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# let's save these to a csv\n",
    "data = [ [ 'jim', 10 ], [ 'bob', 20 ], [ 'jill', 30 ] ]\n",
    "\n",
    "file_name = 'test_file.txt'\n",
    "\n",
    "# write it out\n",
    "with open(file_name, 'w') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    \n",
    "    # header row\n",
    "    writer.writerow(['name', 'age'])\n",
    "    \n",
    "    for d in data:\n",
    "        writer.writerow(d)\n",
    "        \n",
    "# read it back in\n",
    "with open(file_name, 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in list(reader):\n",
    "        print row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': '10', 'name': 'jim'}\n",
      "{'age': '20', 'name': 'bob'}\n",
      "{'age': '30', 'name': 'jill'}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# let's save these dictionaries to a csv\n",
    "data = [ { 'name': 'jim', 'age': 10 }, \n",
    "         { 'name': 'bob', 'age': 20 }, \n",
    "         { 'name': 'jill', 'age': 30 } ]\n",
    "\n",
    "file_name = 'test_file.csv'\n",
    "\n",
    "# write it out\n",
    "with open(file_name, 'w') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=['name','age'])\n",
    "    \n",
    "    writer.writeheader()\n",
    "    \n",
    "    for d in data:\n",
    "        writer.writerow(d)\n",
    "        \n",
    "# read it back in\n",
    "with open(file_name, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in list(reader):\n",
    "        print row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**warning**: CSV returns everything as strings!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ick 1020\n",
      "whew 30\n"
     ]
    }
   ],
   "source": [
    "file_name = 'test_file.csv'\n",
    "\n",
    "# read it back in\n",
    "with open(file_name, 'r') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    rows = list(reader)\n",
    "\n",
    "print \"ick\", rows[0]['age'] + rows[1]['age'] \n",
    "print \"whew\", int(rows[0]['age']) + int(rows[1]['age'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are used to thinking in R (or Pandas) data frames, use the Pandas importer.  It takes care of data type conversions for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>jim</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bob</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jill</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age\n",
       "name     \n",
       "jim    10\n",
       "bob    20\n",
       "jill   30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.DataFrame.from_csv('test_file.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON: saving generic dictionaries and lists\n",
    "If your data structures are not flat, CSV will be a bit of a hassle.  More generic storage of dictionaries and lists can be done with JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'age': 40, u'name': u'bob', u'children': [{u'age': 10, u'name': u'suzanne'}, {u'age': 3, u'name': u'artichoke'}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = {\n",
    "    'name': 'bob',\n",
    "    'age': 40,\n",
    "    'children': [ { 'name': 'suzanne', 'age': 10 }, \n",
    "                  { 'name': 'artichoke', 'age': 3 } ]        \n",
    "    }\n",
    "\n",
    "file_name = 'test_file.json'     \n",
    "\n",
    "with open(file_name, 'w') as f:\n",
    "    json.dump(data, f, indent=2)\n",
    "\n",
    "with open(file_name, 'r') as f:\n",
    "    in_data = json.load(f)\n",
    "\n",
    "print in_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning!**  The json package that comes with Python doesn't like numpy data types, or really any data types that aren't standard Python.  We've added a utility function to the AllenSDK to help with saving these out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'age': 40.0, u'name': u'bob', u'children': [{u'age': 10, u'name': u'suzanne'}, {u'age': 3, u'name': u'artichoke'}]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# the allensdk has code for dealing with this\n",
    "import allensdk.core.json_utilities as json_utilities\n",
    "\n",
    "data = {\n",
    "    'name': 'bob',\n",
    "    'age': np.float32(40), # uh oh! json doesn't like numpy data types\n",
    "    'children': [ { 'name': 'suzanne', 'age': 10 }, \n",
    "                  { 'name': 'artichoke', 'age': 3 } ]        \n",
    "    }\n",
    "\n",
    "file_name = 'test_file.json'     \n",
    "\n",
    "json_utilities.write(file_name, data)\n",
    "\n",
    "in_data = json_utilities.read(file_name)\n",
    "\n",
    "print in_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# string munging\n",
    "Python is really good at slicing and dicing strings.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joined: some strings please\n",
      "split: ['some', 'strings', 'please']\n",
      "my_file_name_03_suffix.txt\n",
      "pi: 3.141593\n",
      "shorter pi: 3.1416\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "strings = [ 'some', 'strings', 'please' ]\n",
    "\n",
    "# join\n",
    "joined = ' '.join(strings)\n",
    "print \"joined:\", joined\n",
    "\n",
    "# split\n",
    "print \"split:\", joined.split()\n",
    "\n",
    "# formatting\n",
    "print 'my_file_name_%02d_%s.txt' % (3, 'suffix')\n",
    "print 'pi: %f' % math.pi\n",
    "print 'shorter pi: %.4f' % math.pi\n",
    "\n",
    "# endswith, startswith\n",
    "print 'file_name.txt'.endswith('txt')\n",
    "print '/home/davidf/file_name.txt'.startswith('/home/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more sophisticated string management, use regular expressions.  The syntax is a little confusing, but it has some nice features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('file', '12')\n",
      "total match file_12.txt\n",
      "group 1 file\n",
      "group 2 12\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# look for non-whitespace characters -> underscore -> digits -> anything\n",
    "m = re.match('(\\S+)_(\\d+).*', \n",
    "             'file_12.txt')\n",
    "\n",
    "# parentheses in the pattern will be stored in match groups\n",
    "print m.groups()\n",
    "\n",
    "# careful about indexing\n",
    "print 'total match', m.group(0)\n",
    "print 'group 1', m.group(1)\n",
    "print 'group 2', m.group(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is really just scratching the surface of regular expressions.  It's a bit of a rabbit hole, so be careful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# files, directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: c:\\workspace\\SWDB-2015\\presentations\\python\\tutorial_part_2\n",
      "splitext: ('file_name', '.txt')\n",
      "absolute: c:\\workspace\\SWDB-2015\\presentations\\python\\tutorial_part_2\\file_name.txt\n",
      "directory: c:\\workspace\\SWDB-2015\\presentations\\python\\tutorial_part_2\n",
      "base name: file_name.txt\n",
      "['.ipynb_checkpoints', 'f1_scripts.py', 'f2_modules.py', 'functions_notebook.ipynb', 'numpy_notebook.ipynb', 'random_data.h5', 'random_data.mat', 'random_data.npy', 'random_data.npz', 'scripts_and_modules_notebook.ipynb', 'strings_and_files.ipynb', 'submodule', 'test_file.csv', 'test_file.json', 'test_file.txt', 'test_file_0.txt', 'test_file_1.txt', 'test_file_2.txt']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# where am I?\n",
    "print \"cwd:\", os.getcwd()\n",
    "\n",
    "# what is this file's extension?\n",
    "file_name = 'file_name.txt'\n",
    "print \"splitext:\", os.path.splitext(file_name)\n",
    "\n",
    "# what is the absolute path of this relative file name?\n",
    "abs_file_name = os.path.abspath(file_name)\n",
    "print \"absolute:\", abs_file_name\n",
    "\n",
    "# what directory is this file in?\n",
    "print \"directory:\", os.path.dirname(abs_file_name)\n",
    "\n",
    "# what is the name of this file, minus all the other stuff?\n",
    "print \"base name:\", os.path.basename(abs_file_name)         \n",
    "\n",
    "# what files are in my cwd?\n",
    "print os.listdir(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing arrays to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import h5py\n",
    "\n",
    "data = np.random.random((100,100))\n",
    "\n",
    "# save it as a numpy file\n",
    "np.save('random_data.npy', data)\n",
    "data = np.load('random_data.npy')\n",
    "\n",
    "# save it as a compressed numpy file (if it's big)\n",
    "np.savez('random_data.npz', data=data)\n",
    "mdict = np.load('random_data.npz')\n",
    "data = mdict['data']\n",
    "\n",
    "# save it as a mat file\n",
    "scipy.io.savemat('random_data.mat', { 'data': data })\n",
    "mdict = scipy.io.loadmat('random_data.mat')\n",
    "data = mdict['data']\n",
    "\n",
    "# save it in an hdf5 file\n",
    "f = h5py.File('random_data.h5', 'w')\n",
    "f['data'] = data\n",
    "f.close()\n",
    "f = h5py.File('random_data.h5', 'r')\n",
    "data = f['data'].value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
